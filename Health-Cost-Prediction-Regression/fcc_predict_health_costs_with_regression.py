# -*- coding: utf-8 -*-
"""fcc_predict_health_costs_with_regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/freeCodeCamp/boilerplate-linear-regression-health-costs-calculator/blob/master/fcc_predict_health_costs_with_regression.ipynb
"""

# Commented out IPython magic to ensure Python compatibility.
# Import libraries. You may or may not use all of these.
#!pip install -q git+https://github.com/tensorflow/docs
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam

# try:
#   # %tensorflow_version only exists in Colab.
# #   %tensorflow_version 2.x
# except Exception:
#   pass
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers

import tensorflow_docs as tfdocs
import tensorflow_docs.plots
import tensorflow_docs.modeling
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, ELU  

# Import data
# !wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv
dataset = pd.read_csv('insurance.csv')
dataset.tail()

# Assuming 'dataset' is your DataFrame
categorical_features = ['sex', 'smoker', 'region']  # Update with actual categorical features
numeric_features = ['age', 'bmi', 'children']  # Update with actual numeric features

# Define preprocessor
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(), categorical_features)])

# Apply transformations
X = dataset.drop('expenses', axis=1)
y = dataset['expenses']
X_processed = preprocessor.fit_transform(X)

# Split the data
X_train, test_dataset, y_train, test_labels = train_test_split(X_processed, y, test_size=0.2, random_state=42)

model = Sequential([
    Dense(128, input_shape=[X_train.shape[1]]),
    LeakyReLU(alpha=0.01),
    Dropout(0.2),  # Slightly increased dropout
    Dense(64),
    LeakyReLU(alpha=0.01),
    Dropout(0.2),  # Consistent dropout for intermediate layers
    Dense(32),
    LeakyReLU(alpha=0.01),
    Dropout(0.2),  # Keep dropout consistent or adjust based on validation performance
    Dense(1)  # Output layer for regression
])

model.compile(optimizer=Adam(learning_rate=0.001),
                  loss='mse',
                  metrics=['mae', 'mse'])

print(model.summary())

early_stop = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, verbose=1, mode='auto', restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)

EPOCHS = 1500

history = model.fit(X_train, y_train, epochs=EPOCHS,
                    validation_split=0.2,
                    callbacks=[early_stop, reduce_lr],batch_size=32,
                    verbose=2)
     

# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.
# Test model by checking how well the model generalizes using the test set.
loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)

print("Testing set Mean Abs Error: {:5.2f} expenses".format(mae))

if mae < 3500:
  print("You passed the challenge. Great job!")
else:
  print("The Mean Abs Error must be less than 3500. Keep trying.")

# Plot predictions.
test_predictions = model.predict(test_dataset).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_labels, test_predictions)
plt.xlabel('True values (expenses)')
plt.ylabel('Predictions (expenses)')
lims = [0, 50000]
plt.xlim(lims)
plt.ylim(lims)
_ = plt.plot(lims,lims)